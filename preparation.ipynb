{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для генерации\n",
    "correct_addresses = []\n",
    "republics = ['Чувашская', 'Чеченская', 'Кабардино-Балкарская']\n",
    "names_rep = ['республика', 'область']\n",
    "city = ['Москва', 'Санкт-Петебург', 'Чебоксары']\n",
    "street_name = ['Моховая', 'Тверская', 'Невская']\n",
    "def generate_address():\n",
    "    for i in range(1000):\n",
    "        new_str = random.choice(republics) + ' ' + random.choice(names_rep) + ', город ' + random.choice(city) + ', улица ' + random.choice(street_name)\n",
    "    \n",
    "    correct_addresses.append(new_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для скрытия слов\n",
    "def masking(s, word):\n",
    "    new_s = s.replace(word, '[MASK]')\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нейросеть для обработки\n",
    "for original in zip(correct_addresses):\n",
    "    print(f\"Original: {original}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize(addresses):\n",
    "    return tokenizer(addresses, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "inputs = tokenize([masking(i, 'Республика') for i in correct_addresses])\n",
    "labels = tokenize(correct_addresses)\n",
    "\n",
    "\n",
    "class AddressCorrector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddressCorrector, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=tokenizer.vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs\n",
    "\n",
    "model = AddressCorrector()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels['input_ids'])\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "def train(model, dataloader, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, label_ids = batch\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=label_ids)\n",
    "            loss = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "train(model, dataloader, optimizer)\n",
    "\n",
    "def predict(model, address):\n",
    "    model.eval()\n",
    "    inputs = tokenize([address])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    predicted_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "    return tokenizer.decode(predicted_ids[0])\n",
    "\n",
    "test_address = \"Чувашская ресублика, город Чебоксары, улица Моховая\"\n",
    "corrected_address = predict(model, test_address)\n",
    "print(f\"Original: {test_address}\")\n",
    "print(f\"Corrected: {corrected_address}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# второй вариант обработки, приведен для примера\n",
    "\n",
    "string = '428023 Чувашская Република, город Чебоксары, бульвар Миттова, '\n",
    "words = string.split()\n",
    "for i in range(len(words)):\n",
    "    new_word = words[i].strip(',')\n",
    "    dist = nltk.edit_distance('Республика', new_word)\n",
    "    if 1 <= dist <= 3:\n",
    "        if words[i][-1] == ',':\n",
    "            words[i] = 'Республика' + ','\n",
    "        else:\n",
    "            words[i] = 'Республика'\n",
    "\n",
    "' '.join(words)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
